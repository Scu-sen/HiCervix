{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "from pprint import pprint\n",
    "# import cv2\n",
    "# import imageio\n",
    "# import imagesize\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby,chain,combinations\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, cohen_kappa_score, accuracy_score\n",
    "from sklearn.metrics import average_precision_score, roc_curve, auc, precision_recall_curve, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree, search\n",
    "from anytree.importer import JsonImporter\n",
    "from anytree.exporter import JsonExporter, DotExporter\n",
    "import lzma\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function for processing the hierarchical classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_level_name(class_name, level=1):\n",
    "    path_node_classes = classname_paths[class_name]\n",
    "    if len(path_node_classes)>level:\n",
    "        return path_node_classes[level]\n",
    "    else:\n",
    "        return None\n",
    "def find_level_name_v2(class_name, level=1):\n",
    "    \"\"\"fill the finest label using the coarse lable\"\"\"\n",
    "    path_node_classes = classname_paths[class_name]\n",
    "    if len(path_node_classes)>level:\n",
    "        return path_node_classes[level]\n",
    "    else:\n",
    "        return path_node_classes[-1]\n",
    "def lca_height(class_name1, class_name2, logarithmic=True):\n",
    "    \"\"\"lowest common ancestor height, taking the level into acount np.log(1+height)\n",
    "    \"\"\"\n",
    "    node1 = search.find_by_attr(TCT, class_name1)\n",
    "    node2 = search.find_by_attr(TCT, class_name2)\n",
    "    node1_path_names = [x.name for x in node1.path]\n",
    "    node2_path_names = [x.name for x in node2.path]\n",
    "    if len(node1_path_names) == len(node2_path_names):\n",
    "        height = 0\n",
    "        for name1, name2 in list(zip(node1_path_names, node2_path_names))[::-1]:\n",
    "            if name1==name2:\n",
    "                return np.log(1+height) if logarithmic else height\n",
    "            else:\n",
    "                height +=1\n",
    "    #             return name1\n",
    "    else:\n",
    "        common_length = len(set(node1_path_names).intersection(set(node2_path_names)))\n",
    "        longest_length = max(len(node1_path_names), len(node2_path_names))\n",
    "        height = longest_length - common_length\n",
    "        return height\n",
    "def tree2list(node):\n",
    "    res = []\n",
    "    if len(node.siblings)== 0:\n",
    "        res.append([node.name])\n",
    "    if len(node.children) > 0:\n",
    "        res.append([x.name for x in node.children])\n",
    "    for x in node.children:\n",
    "        res.extend(tree2list(x))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lca_height('AGC-NOS','LSIL', logarithmic=False)\n",
    "# lca_height('AGC-NOS','AGC-NOS', logarithmic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_df(df,num=200, name='grade', classes=None):\n",
    "    if classes is None:\n",
    "        name_set = list(set(df[name]))\n",
    "    else:\n",
    "        name_set = list(set(df[name]).intersection(classes))\n",
    "    print(name_set)\n",
    "    df_sampled = pd.concat([df[df[name]==x].sample(min(num, df[df[name]==x].shape[0]), random_state=23) for x in name_set])\n",
    "    return df_sampled\n",
    "\n",
    "def df_v2(df):\n",
    "    df_res = df.copy()\n",
    "    print('Using all data')\n",
    "    df_res['level_2'] = df_res['class_name'].apply(lambda x: find_level_name_v2(x, level=2))\n",
    "    df_res['level_3'] = df_res['class_name'].apply(lambda x: find_level_name_v2(x, level=3))\n",
    "    return df_res\n",
    "def filter_df(df_in):\n",
    "    df = df_in.copy()\n",
    "    df = df[df['class_name'].isin(selected_classes)]\n",
    "    df['class_id'] = df['class_name'].map(classes2id)\n",
    "    return df\n",
    "\n",
    "def evaluate(df, method=2, to_level=3, cal_auc=True):\n",
    "    df_res = df.copy()\n",
    "    if method==1:\n",
    "        print('Using partial data...')  # \n",
    "    else:\n",
    "        print('Using all data...')   # default way\n",
    "        df_res['level_1'] = df_res['class_name'].apply(lambda x: find_level_name_v2(x, level=1))\n",
    "        df_res['level_2'] = df_res['class_name'].apply(lambda x: find_level_name_v2(x, level=2))\n",
    "        df_res['level_3'] = df_res['class_name'].apply(lambda x: find_level_name_v2(x, level=3))\n",
    "        df_res['level_1_id'] = df_res['level_1'].map(level_1_names2id)\n",
    "        df_res['level_2_id'] = df_res['level_2'].apply(lambda x: level_2_names2id.get(x, -1))\n",
    "        df_res['level_3_id'] = df_res['level_3'].apply(lambda x: level_3_names2id.get(x, -1))\n",
    "    acc_lst = []\n",
    "    hierarchical_distances = []\n",
    "    auc_lst = []\n",
    "    f1_score_lst = []\n",
    "    middle_class_metric = []\n",
    "    #### level 1\n",
    "    level_1_acc = accuracy_score(df_res['level_1'], df_res['level_1_pred'])\n",
    "    acc_lst.append(level_1_acc)\n",
    "    level_1_distance = df_res[['level_1','level_1_pred']].apply(lambda x: lca_height(x[0], x[1]), axis =1).mean() # 同层的距离\n",
    "    hierarchical_distances.append(level_1_distance)\n",
    "    if cal_auc:\n",
    "        auc_lst.append(roc_auc_score(df_res['level_1_id'], df_res.filter(regex='order*',axis=1), multi_class='ovr'))\n",
    "    f1_score_lst.append(f1_score(df_res['level_1'], df_res['level_1_pred'], average='macro'))\n",
    "\n",
    "    print('Level_1 accuracy: {:.4f}'.format(level_1_acc))\n",
    "    print('level_1 hierarchical distanse: {:.4f}'.format(level_1_distance))\n",
    "    print('#'*30)\n",
    "    \n",
    "    #### level 2\n",
    "    df_level2 = df_res[(~df_res['level_2'].isna())&(df_res['level_2']!='AGC')] # 不考虑AGC\n",
    "    level_2_distance = df_level2[['level_2','level_2_pred']].apply(lambda x: lca_height(x[0], x[1]), axis =1).mean()\n",
    "    hierarchical_distances.append(level_2_distance)\n",
    "\n",
    "    level_2_acc = accuracy_score(df_level2['level_2'], df_level2['level_2_pred'])\n",
    "    acc_lst.append(level_2_acc)\n",
    "    if cal_auc:\n",
    "        auc_lst.append(roc_auc_score(df_level2['level_2_id'], df_level2.filter(regex='family*',axis=1), multi_class='ovr'))\n",
    "    f1_score_lst.append(f1_score(df_level2['level_2'], df_level2['level_2_pred'], average='macro'))\n",
    "    print('Level_2 accuracy: {:.4f}'.format(level_2_acc))\n",
    "    print('level_2 hierarchical distande: {:.4f}'.format(level_2_distance))\n",
    "    print('#'*30)\n",
    "    \n",
    "    if to_level == 2:\n",
    "        pass\n",
    "    else:\n",
    "        #### level 3\n",
    "        df_level3 = df_res[(~df_res['level_3'].isna())&(~df_res['level_3'].isin(['AGC','AGC-NOS', 'ADC']))]\n",
    "    #     df_level3_normalcls = df_level3[~df_level3['level_3_pred'].isna()]\n",
    "        level_3_distance = df_level3[['level_3','level_3_pred']].apply(lambda x: lca_height(x[0], x[1]), axis =1).mean()\n",
    "        hierarchical_distances.append(level_3_distance)\n",
    "    #     df_level3.fillna(value='undercls',inplace=True)\n",
    "        ## only consider intra-level confusion \n",
    "        level_3_acc = accuracy_score(df_level3['level_3'], df_level3['level_3_pred'])\n",
    "        acc_lst.append(level_3_acc)\n",
    "        if cal_auc:\n",
    "            auc_lst.append(roc_auc_score(df_level3['level_3_id'], df_level3.filter(regex='species*',axis=1), multi_class='ovr'))\n",
    "        f1_score_lst.append(f1_score(df_level3['level_3'], df_level3['level_3_pred'], average='macro'))\n",
    "        print('Level_3 accuracy: {:.4f}'.format(level_3_acc))\n",
    "        print('level_3 hierarchical distande: {:.4f}'.format(level_3_distance))\n",
    "        print('#'*30)\n",
    "\n",
    "        print('Average accuracy: {:.4f}'.format(np.mean(acc_lst)))\n",
    "        print('Average hierarchical distance: {:.4f}'.format(np.mean(hierarchical_distances)))\n",
    "    res_data = acc_lst + hierarchical_distances + auc_lst# + f1_score_lst\n",
    "    return res_data\n",
    "\n",
    "def add_level_pred(df):\n",
    "    df['level_1_pred'] = [x.split('_')[-1] for x in df.filter(regex='order*',axis=1).idxmax(axis=1)]\n",
    "    df['level_2_pred'] = [x.split('_')[-1] for x in df.filter(regex='family*',axis=1).idxmax(axis=1)]\n",
    "    df['level_3_pred'] = [x.split('_')[-1] for x in df.filter(regex='species*',axis=1).idxmax(axis=1)]\n",
    "    \n",
    "    df['level_1_pred_score'] = df.filter(regex='order*',axis=1).max(axis=1)\n",
    "    df['level_2_pred_score'] = df.filter(regex='family*',axis=1).max(axis=1)\n",
    "    df['level_3_pred_score'] = df.filter(regex='species*',axis=1).max(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_order_pred_score(df):\n",
    "    for class_name in level_1_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        leaf_node_names =[x.name for x in  class_name_node.children]\n",
    "        df['order_{}'.format(class_name)] = df[['family_{}'.format(x) for x in leaf_node_names]].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_order_family_pred_score(df):\n",
    "    for class_name in level_1_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        leaf_node_names =[x.name for x in  class_name_node.leaves]\n",
    "#         print(['species_{}'.format(x) for x in leaf_node_names])\n",
    "        df['order_{}'.format(class_name)] = df[['species_{}'.format(x) for x in leaf_node_names]].sum(axis=1)\n",
    "    \n",
    "    for class_name in level_2_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        leaf_node_names =[x.name for x in  class_name_node.leaves]\n",
    "        df['family_{}'.format(class_name)] = df[['species_{}'.format(x) for x in leaf_node_names]].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def conditional_pred_score(df):\n",
    "    for class_name in level_1_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        path_node_classes = [x.name for x in class_name_node.path][1:]\n",
    "        df['order_{}'.format(class_name)] = df[path_node_classes].prod(axis=1)\n",
    "    \n",
    "    for class_name in level_2_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        path_node_classes = [x.name for x in class_name_node.path][1:]\n",
    "        df['family_{}'.format(class_name)] = df[path_node_classes].prod(axis=1)\n",
    "    \n",
    "    for class_name in level_3_names:\n",
    "        class_name_node = search.find_by_attr(TCT, class_name)\n",
    "        path_node_classes = [x.name for x in class_name_node.path][1:]\n",
    "        df['species_{}'.format(class_name)] = df[path_node_classes].prod(axis=1)\n",
    "    return df\n",
    "\n",
    "def fgvc_helper(df_species_fgvc):\n",
    "    df_species_fgvc['pred_class'] = [level_3_names.index(x.split('_')[-1]) for x in df_species_fgvc.filter(regex='species*',axis=1).idxmax(axis=1)]\n",
    "    df_species_fgvc['level_3_pred']=df_species_fgvc['pred_class'].map(dict(zip(range(len(level_3_names)),level_3_names)))\n",
    "    df_species_fgvc['level_2_pred']=df_species_fgvc['level_3_pred'].apply(lambda x: find_level_name_v2(x, level=2))\n",
    "    df_species_fgvc['level_1_pred']=df_species_fgvc['level_3_pred'].apply(lambda x: find_level_name_v2(x, level=1))\n",
    "    return df_species_fgvc\n",
    "\n",
    "def get_res_summary(res_lst, model_lst):\n",
    "    df_summary = pd.DataFrame(res_lst,\n",
    "             index=model_lst,\n",
    "            columns=['level_1_acc', 'level_2_acc', 'level_3_acc', 'level_1_hier_dist', 'level_2_hier_dist', 'level_3_hier_dist',\n",
    "                     'level_1_auc', 'level_2_auc', 'level_3_auc', \n",
    "                     #'level_1_f1_score', 'level_2_f1_score', 'level_3_f1_score',\n",
    "                    #'AGC_acc', 'AGC_hier_dist', 'AGC-NOS/ADC_acc', 'AGC-NOS/ADC_hier_dist'\n",
    "                    ])\n",
    "    df_summary['avg_acc']=df_summary[['level_1_acc','level_2_acc','level_3_acc']].mean(axis=1)\n",
    "    df_summary['avg_hier_dist']=df_summary[['level_1_hier_dist','level_2_hier_dist','level_3_hier_dist']].mean(axis=1)\n",
    "    columns = ['level_1_acc', 'level_2_acc', 'level_3_acc', 'avg_acc', 'level_1_hier_dist', 'level_2_hier_dist', 'level_3_hier_dist', 'avg_hier_dist',\n",
    "               'level_1_auc', 'level_2_auc', 'level_3_auc', \n",
    "               #'level_1_f1_score', 'level_2_f1_score', 'level_3_f1_score',\n",
    "                        #'AGC_acc', 'AGC_hier_dist', 'AGC-NOS/ADC_acc', 'AGC-NOS/ADC_hier_dist'\n",
    "              ]\n",
    "    df_summary = df_summary[columns]\n",
    "    return df_summary.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hierarchy class in HiCervix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### hierarchical tree construction for HiCervix\n",
    "## the full names of the acronyms are listed in dataset/hierarchy_classification/version2023/hierarchy_names.csv\n",
    "TCT = Node(\"TCT\")\n",
    "negative = Node(\"negative\",parent=TCT) \n",
    "ASC = Node(\"ASC\", parent=TCT) \n",
    "AGC = Node(\"AGC\", parent=TCT) \n",
    "microbe = Node(\"microbe\",parent=TCT)  ## microbe is the class  Organisms\n",
    "\n",
    "ASCUS = Node(\"ASC-US\", parent=ASC)\n",
    "LSIL = Node(\"LSIL\", parent=ASC)\n",
    "ASCH = Node(\"ASC-H\", parent=ASC)\n",
    "HSIL = Node(\"HSIL\", parent=ASC)\n",
    "SCC = Node(\"SCC\", parent=ASC)\n",
    "\n",
    "AGCNOS = Node(\"AGC-NOS\", parent=AGC)\n",
    "AGCFN = Node(\"AGC-FN\", parent=AGC)\n",
    "ADC = Node(\"ADC\", parent=AGC)\n",
    "\n",
    "AGCNOS1 = Node(\"AGC-ECC-NOS\", parent=AGCNOS)\n",
    "AGCNOS2 = Node(\"AGC-EMC-NOS\", parent=AGCNOS)\n",
    "\n",
    "ADC1 = Node(\"ADC-ECC\", parent=ADC)\n",
    "ADC2 = Node(\"ADC-EMC\", parent=ADC)\n",
    "\n",
    "normal = Node(\"Normal\", parent=negative)\n",
    "endocervical = Node(\"ECC\", parent=negative)\n",
    "xiufu = Node(\"RPC\", parent=negative)\n",
    "huasheng = Node(\"MPC\", parent=negative)\n",
    "glucose = Node(\"PG\", parent=negative)\n",
    "Atrophy = Node(\"Atrophy\", parent=negative)\n",
    "EMC = Node(\"EMC\", parent=negative)\n",
    "HCG = Node(\"HCG\", parent=negative)\n",
    "\n",
    "FUNGI = Node(\"FUNGI\", parent=microbe)\n",
    "ACTINO = Node(\"ACTINO\", parent=microbe)\n",
    "TRI = Node(\"TRI\", parent=microbe)\n",
    "HSV = Node(\"HSV\", parent=microbe)\n",
    "CC = Node(\"CC\", parent=microbe)\n",
    "\n",
    "# darkclusters = Node(\"HCG\", parent=negative)\n",
    "# DotExporter(TCT_en).to_picture(\"TCT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### hierarchical tree construction for HiCervix,chinese version if needed \n",
    "## which could also serve as the dictionary for english names and chinese names tranlation (if needed)\n",
    "# TCT = Node(\"TCT\")\n",
    "# ASC = Node(\"ASC\", parent=TCT) # 鳞状上皮病变\n",
    "# AGC = Node(\"AGC\", parent=TCT) # 腺上皮病变\n",
    "# microbe = Node(\"microbe\",parent=TCT) #微生物类\n",
    "# negative = Node(\"negative\",parent=TCT) # 其他类\n",
    "# # OTHERS = Node(\"OTHERS\",parent=TCT) # 其他病变类\n",
    "\n",
    "# # 鳞状上皮病变\n",
    "# ASCUS = Node(\"ASC-US\", parent=ASC)\n",
    "# LSIL = Node(\"LSIL\", parent=ASC)\n",
    "# ASCH = Node(\"ASC-H\", parent=ASC)\n",
    "# HSIL = Node(\"HSIL\", parent=ASC)\n",
    "# SCC = Node(\"SCC\", parent=ASC)\n",
    "\n",
    "# # 腺上皮病变\n",
    "# AGCNOS = Node(\"AGC-NOS\", parent=AGC)\n",
    "# AGCFN = Node(\"AGC-FN\", parent=AGC)\n",
    "# ADC = Node(\"ADC\", parent=AGC)\n",
    "\n",
    "# AGCNOS1 = Node(\"非典型子宫内膜细胞\", parent=AGCNOS)\n",
    "# AGCNOS2 = Node(\"非典型颈管腺细胞\", parent=AGCNOS)\n",
    "\n",
    "# ADC1 = Node(\"颈管腺癌\", parent=ADC)\n",
    "# ADC2 = Node(\"子宫内膜腺癌\", parent=ADC)\n",
    "\n",
    "# TRI = Node(\"滴虫\", parent=microbe)\n",
    "# CC = Node(\"细菌性阴道病\", parent=microbe)\n",
    "# FUNGI = Node(\"放线菌\", parent=microbe)\n",
    "# ACTINO = Node(\"念珠菌\", parent=microbe)\n",
    "# HSV = Node(\"疱疹病毒感染\", parent=microbe)\n",
    "# # CMV = Node(\"多核巨细胞\", parent=microbe)\n",
    "\n",
    "# EM = Node(\"子宫内膜细胞\", parent=negative)\n",
    "# PM = Node(\"萎缩性改变\", parent=negative)\n",
    "# endocervical = Node(\"宫颈管细胞\", parent=negative)\n",
    "# xiufu = Node(\"修复细胞\", parent=negative)\n",
    "# huasheng = Node(\"化生细胞\", parent=negative)\n",
    "# glucose = Node(\"糖原溶解细胞\", parent=negative)\n",
    "# darkclusters = Node(\"深染细胞团\", parent=negative)\n",
    "# normal = Node(\"其他正常细胞\", parent=negative)\n",
    "# scancer = Node(\"小细胞癌\", parent=OTHERS)\n",
    "# TCT.leaves\n",
    "# tmp = tree2list(TCT)\n",
    "# len(list(chain(*tmp[1:])))\n",
    "# DotExporter(TCT).to_picture(\"TCT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chn2english_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print([chn2english_names[x] for x in level_3_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total annotated classes: 26\n",
      "Number of level 1 classes: 4\n",
      "Number of level 2 classes: 21\n",
      "Number of level 3 classes: 23\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG', 'ASC-US', 'LSIL',\n",
    "               'ASC-H', 'HSIL', 'SCC', 'AGC', 'AGC-NOS', 'AGC-FN', 'ADC', 'AGC-ECC-NOS', 'AGC-EMC-NOS', \n",
    "               'ADC-ECC', 'ADC-EMC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "level_1_names = ['negative','ASC','AGC','microbe']\n",
    "level_2_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG ', 'ASC-US', 'LSIL', \n",
    "                 'ASC-H', 'HSIL', 'SCC', 'AGC-NOS', 'AGC-FN', 'ADC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "level_3_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG ', 'ASC-US', 'LSIL', 'ASC-H', 'HSIL', 'SCC', 'AGC-FN', \n",
    "                 'AGC-ECC-NOS', 'AGC-EMC-NOS', 'ADC-ECC', 'ADC-EMC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "# class_names = ['其他正常细胞','宫颈管细胞','修复细胞','化生细胞','糖原溶解细胞','萎缩性改变','子宫内膜细胞','深染细胞团',\n",
    "#                'ASC-US','LSIL','ASC-H','HSIL', 'SCC',\n",
    "#                'AGC','AGC-NOS','AGC-FN','ADC',  \n",
    "#                 '非典型颈管腺细胞','非典型子宫内膜细胞', '颈管腺癌','子宫内膜腺癌',\n",
    "#                '念珠菌','放线菌','滴虫','疱疹病毒感染','细菌性阴道病']\n",
    "# level_1_names = ['negative','ASC','AGC','microbe']\n",
    "# level_2_names = ['其他正常细胞','宫颈管细胞','修复细胞','化生细胞','糖原溶解细胞','萎缩性改变','子宫内膜细胞','深染细胞团',\n",
    "#                'ASC-US','LSIL','ASC-H','HSIL', 'SCC',\n",
    "#                 'AGC-NOS','AGC-FN','ADC',\n",
    "#                '念珠菌','放线菌','滴虫','疱疹病毒感染','细菌性阴道病']\n",
    "# # no intermediate classes such as AGC\n",
    "# level_3_names = ['其他正常细胞','宫颈管细胞','修复细胞','化生细胞','糖原溶解细胞','萎缩性改变','子宫内膜细胞','深染细胞团',\n",
    "#                'ASC-US','LSIL','ASC-H','HSIL', 'SCC',\n",
    "#                 'AGC-FN', #'AGC','AGC-NOS', 'ADC',\n",
    "#                 '非典型颈管腺细胞','非典型子宫内膜细胞', '颈管腺癌','子宫内膜腺癌',\n",
    "#                '念珠菌','放线菌','滴虫','疱疹病毒感染','细菌性阴道病']\n",
    "level_1_names2id = dict(zip(level_1_names, range(len(level_1_names))))\n",
    "level_2_names2id = dict(zip(level_2_names, range(len(level_2_names))))\n",
    "level_3_names2id = dict(zip(level_3_names, range(len(level_3_names))))\n",
    "\n",
    "level_names = [level_1_names, level_2_names,level_3_names,]\n",
    "classname2newid = dict(zip(class_names, range(len(class_names))))\n",
    "newid2classname= {v:k for k,v in classname2newid.items()}\n",
    "print('Number of total annotated classes: {}'.format(len(class_names)))\n",
    "for i in range(3):\n",
    "    print('Number of level {} classes: {}'.format(i+1, len(level_names[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classname_paths = {}\n",
    "for class_name in class_names:\n",
    "    # print(class_name)\n",
    "    class_name_node = search.find_by_attr(TCT, class_name)\n",
    "    path_node_classes = [x.name for x in class_name_node.path]#[1:] #exclude the root node of 'TCT'\n",
    "#     print('The nodes in the path (from root node) to reach the nodes of {}'.format(class_name))\n",
    "#     print(path_node_classes)\n",
    "    classname_paths[class_name] = path_node_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': ['TCT', 'negative', 'Normal'],\n",
       " 'ECC': ['TCT', 'negative', 'ECC'],\n",
       " 'RPC': ['TCT', 'negative', 'RPC'],\n",
       " 'MPC': ['TCT', 'negative', 'MPC'],\n",
       " 'PG': ['TCT', 'negative', 'PG'],\n",
       " 'Atrophy': ['TCT', 'negative', 'Atrophy'],\n",
       " 'EMC': ['TCT', 'negative', 'EMC'],\n",
       " 'HCG': ['TCT', 'negative', 'HCG'],\n",
       " 'ASC-US': ['TCT', 'ASC', 'ASC-US'],\n",
       " 'LSIL': ['TCT', 'ASC', 'LSIL'],\n",
       " 'ASC-H': ['TCT', 'ASC', 'ASC-H'],\n",
       " 'HSIL': ['TCT', 'ASC', 'HSIL'],\n",
       " 'SCC': ['TCT', 'ASC', 'SCC'],\n",
       " 'AGC': ['TCT', 'AGC'],\n",
       " 'AGC-NOS': ['TCT', 'AGC', 'AGC-NOS'],\n",
       " 'AGC-FN': ['TCT', 'AGC', 'AGC-FN'],\n",
       " 'ADC': ['TCT', 'AGC', 'ADC'],\n",
       " 'AGC-ECC-NOS': ['TCT', 'AGC', 'AGC-NOS', 'AGC-ECC-NOS'],\n",
       " 'AGC-EMC-NOS': ['TCT', 'AGC', 'AGC-NOS', 'AGC-EMC-NOS'],\n",
       " 'ADC-ECC': ['TCT', 'AGC', 'ADC', 'ADC-ECC'],\n",
       " 'ADC-EMC': ['TCT', 'AGC', 'ADC', 'ADC-EMC'],\n",
       " 'FUNGI': ['TCT', 'microbe', 'FUNGI'],\n",
       " 'ACTINO': ['TCT', 'microbe', 'ACTINO'],\n",
       " 'TRI': ['TCT', 'microbe', 'TRI'],\n",
       " 'HSV': ['TCT', 'microbe', 'HSV'],\n",
       " 'CC': ['TCT', 'microbe', 'CC']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classname_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classname_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchy for making better mistakes\n",
    "tct = Tree.fromstring(\"(TCT (negative (Normal Normal) (ECC ECC) (RPC RPC) (MPC MPC) (PG PG) (Atrophy Atrophy) (EMC EMC) (HCG HCG))  \\\n",
    "                     (ASC (ASC-US ASC-US) (LSIL LSIL) (ASC-H ASC-H) (HSIL HSIL) (SCC SCC))   \\\n",
    "                     (AGC (AGC-FN AGC-FN) (AGC-NOS AGC-ECC-NOS AGC-EMC-NOS) (ADC ADC-ECC ADC-EMC)) \\\n",
    "                     (microbe (FUNGI FUNGI) (ACTINO ACTINO) (TRI TRI) (HSV HSV) (CC CC)) \\\n",
    "                     )\")\n",
    "tct_2level = Tree.fromstring(\"(TCT (negative Normal  ECC RPC MPC  PG  Atrophy  EMC  HCG)  \\\n",
    "                     (ASC  ASC-US  LSIL  ASC-H  HSIL  SCC)   \\\n",
    "                     (AGC AGC-FN  AGC-NOS  ADC ) \\\n",
    "                     (microbe  FUNGI  ACTINO  TRI  HSV  CC) \\\n",
    "                     )\")\n",
    "\n",
    "# tct = Tree.fromstring(\"(TCT (negative (其他正常细胞 其他正常细胞) (宫颈管细胞 宫颈管细胞) (修复细胞 修复细胞) (化生细胞 化生细胞) (糖原溶解细胞 糖原溶解细胞) (萎缩性改变 萎缩性改变) (子宫内膜细胞 子宫内膜细胞) (深染细胞团 深染细胞团))  \\\n",
    "#                      (ASC (ASC-US ASC-US) (LSIL LSIL) (ASC-H ASC-H) (HSIL HSIL) (SCC SCC))   \\\n",
    "#                      (AGC (AGC-FN AGC-FN) (AGC-NOS 非典型颈管腺细胞 非典型子宫内膜细胞) (ADC 颈管腺癌 子宫内膜腺癌)) \\\n",
    "#                      (microbe (念珠菌 念珠菌) (放线菌 放线菌) (滴虫 滴虫) (疱疹病毒感染 疱疹病毒感染) (细菌性阴道病 细菌性阴道病)) \\\n",
    "#                      )\")\n",
    "# tct_2level = Tree.fromstring(\"(TCT (negative 其他正常细胞  宫颈管细胞 修复细胞 化生细胞  糖原溶解细胞  萎缩性改变  子宫内膜细胞  深染细胞团)  \\\n",
    "#                      (ASC  ASC-US  LSIL  ASC-H  HSIL  SCC)   \\\n",
    "#                      (AGC AGC-FN  AGC-NOS  ADC ) \\\n",
    "#                      (microbe  念珠菌  放线菌  滴虫  疱疹病毒感染  细菌性阴道病) \\\n",
    "#                      )\")\n",
    "\n",
    "# hierarchy for making better mistakes\n",
    "tct_distances = {}\n",
    "all_names = set(level_1_names + level_2_names + level_3_names)\n",
    "for name1 in all_names:\n",
    "    for name2 in all_names:\n",
    "        tct_distances[(name1,name2)] = lca_height(name1, name2)\n",
    "# with open('classification_hierarchy/making-better-mistakes/data/tct_tree.pkl','wb') as fi:\n",
    "#     pickle.dump(tct, fi)\n",
    "\n",
    "# with open('classification_hierarchy/making-better-mistakes-2level/data/tct_tree.pkl','wb') as fi:\n",
    "#     pickle.dump(tct_2level, fi)\n",
    "# with open('classification_hierarchy/making-better-mistakes/data/tct_distances.pkl','wb') as fi:\n",
    "#     pickle.dump(tct_distances, fi)\n",
    "\n",
    "# with open('classification_hierarchy/making-better-mistakes/data/tct_tree.pkl','rb') as fi:\n",
    "#     tree_data = pickle.load(fi)\n",
    "# tree_data\n",
    "# with lzma.open('/classification_hierarchy/making-better-mistakes/data/imagenet_ilsvrc_distances.pkl.xz', \"rb\") as f:\n",
    "#     tmp = pickle.load(f)\n",
    "# #     distance_data = DistanceDict(pickle.load(f))\n",
    "#     distance_data = DistanceDict(tmp)\n",
    "level_names_dict = dict(zip(['order','family','species'], level_names))\n",
    "# with open('dataset/hierarchy_classification/version3/level_names_dict.pkl','wb') as fi:\n",
    "#     pickle.dump(level_names_dict, fi)\n",
    "# with open('dataset/hierarchy_classification/version3/level_names_dict.pkl','rb') as fo:\n",
    "#     tmp = pickle.load(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for multi-head and FGoN\n",
    "trees =[]\n",
    "trees_names = []\n",
    "trees_dict = {}\n",
    "def find_class_id(class_name, lst):\n",
    "    try:\n",
    "        class_id = lst.index(class_name)\n",
    "    except:\n",
    "        class_id = -1\n",
    "    return class_id\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_name_node = search.find_by_attr(TCT, class_name)\n",
    "    path_node_classes = [x.name for x in class_name_node.path]#[1:] #exclude the root node of 'TCT'\n",
    "    extended_node_names = [find_level_name_v2(class_name, i) for i in range(1,4)]\n",
    "    extended_node_ids = [find_class_id(x, level_names[i]) for i, x in enumerate(extended_node_names)] #level_names[i].index(x)\n",
    "    trees.append(extended_node_ids)\n",
    "    trees_names.append(extended_node_names)\n",
    "    trees_dict[class_name]=extended_node_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preprocessing for different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HierSwin methods and making better mistakes\n",
    "datasets = ['train.csv','val.csv','test.csv']\n",
    "# datasets = ['train_image_path.csv','val_image_path.csv','test_image_path.csv']\n",
    "csv_dir = 'dataset/hierarchy_classification/version2023/'\n",
    "for dataset in datasets:\n",
    "    csv_file = osp.join(csv_dir, dataset)\n",
    "    df_tmp = pd.read_csv(csv_file)\n",
    "    df_tmp = df_tmp[df_tmp['class_name'].isin(level_3_names)]\n",
    "    df_tmp['level_3_id'] = df_tmp['class_name'].map(dict(zip(level_3_names,range(len(level_3_names)))))\n",
    "    df_tmp.to_csv(csv_file.replace('.csv','_mbm.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HRN\n",
    "datasets = ['train_image_path.csv']#,'val_image_path.csv','test_image_path.csv']\n",
    "csv_dir = 'dataset/hierarchy_classification/version2023/'\n",
    "for dataset in datasets:\n",
    "    csv_file = osp.join(csv_dir, dataset)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['level_1_id'] = df['level_1'].map(level_1_names2id)\n",
    "    df['level_2_name'] = df['class_name'].apply(lambda x: find_level_name_v2(x, level=2))\n",
    "    df['level_3_name'] = df['class_name'].apply(lambda x: find_level_name_v2(x, level=3))\n",
    "    df['level_2_id'] = df['level_2_name'].apply(lambda x: level_2_names2id.get(x, -1))\n",
    "    df['level_3_id'] = df['level_3_name'].apply(lambda x: level_3_names2id.get(x, -1))\n",
    "    #df[['image_path', 'image_name', 'class_id', 'level_1_id', 'level_2_id', 'level_3_id']].to_csv(csv_file.replace('.csv','_hrn.csv')) #encoding='utf-8-sig', ,  index=False\n",
    "    df[['image_path', 'image_name', 'class_id', 'level_1_id', 'level_2_id', 'level_3_id']].to_csv('/mnt/group-ai-medical-abp/private/daviddecai/tmp.csv') #encoding='utf-8-sig', ,  index=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fine-grained visual classification\n",
    "\n",
    "# level_3 finegrained，intermediate classes such as AGC,'AGC-NOS','ADC' are removed \n",
    "csv_dir = 'dataset/hierarchy_classification/version2023'\n",
    "datasets = ['train','val','test']\n",
    "for dataset in datasets:\n",
    "    df_tmp = pd.read_csv(osp.join(csv_dir, dataset + '.csv'))\n",
    "    #df_tmp = df_tmp[~df_tmp['class_name'].isin(['AGC','AGC-NOS','ADC'])] \n",
    "    df_tmp = df_v2(df_tmp)\n",
    "    #df_tmp['level_3_id']= df_tmp['level_3'].map(dict(zip(level_3_names, range(len(level_3_names)))))\n",
    "    df_tmp['level_3_id']= df_tmp['level_3'].apply(lambda x: level_3_names2id.get(x, -1))\n",
    "    df_tmp.to_csv(osp.join(csv_dir, dataset + '_keep_species_all.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8809\n",
      "level_1 hierarchical distanse: 0.0826\n",
      "##############################\n",
      "Level_2 accuracy: 0.6406\n",
      "level_2 hierarchical distande: 0.3028\n",
      "##############################\n",
      "Level_3 accuracy: 0.6389\n",
      "level_3 hierarchical distande: 0.3605\n",
      "##############################\n",
      "Average accuracy: 0.7201\n",
      "Average hierarchical distance: 0.2486\n"
     ]
    }
   ],
   "source": [
    "df_multi = pd.read_csv('classification_hierarchy/vanilla_single/output_0512_384/test_image_path_res.csv')\n",
    "df_multi = add_level_pred(df_multi)\n",
    "multi2 = evaluate(df_multi,method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.9048\n",
      "level_1 hierarchical distanse: 0.0660\n",
      "##############################\n",
      "Level_2 accuracy: 0.7577\n",
      "level_2 hierarchical distande: 0.2072\n",
      "##############################\n",
      "Level_3 accuracy: 0.7566\n",
      "level_3 hierarchical distande: 0.2396\n",
      "##############################\n",
      "Average accuracy: 0.8064\n",
      "Average hierarchical distance: 0.1709\n"
     ]
    }
   ],
   "source": [
    "df_mbm = pd.read_csv('classification_hierarchy/making-better-mistakes/hxe_tct_alpha0.4_0512_384/test_image_path_mbm_res.csv')\n",
    "df_mbm = add_order_family_pred_score(df_mbm)\n",
    "df_mbm = add_level_pred(df_mbm)\n",
    "mbm2 = evaluate(df_mbm,method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.9208\n",
      "level_1 hierarchical distanse: 0.0549\n",
      "##############################\n",
      "Level_2 accuracy: 0.7836\n",
      "level_2 hierarchical distande: 0.1821\n",
      "##############################\n",
      "Level_3 accuracy: 0.7835\n",
      "level_3 hierarchical distande: 0.2082\n",
      "##############################\n",
      "Average accuracy: 0.8293\n",
      "Average hierarchical distance: 0.1484\n"
     ]
    }
   ],
   "source": [
    "## HierSwin = making better mistakes + Swin-Transformer\n",
    "df_mbm_swint = pd.read_csv('test_image_path_mbm_res_api_swint_epoch30.csv')\n",
    "df_mbm_swint = add_order_family_pred_score(df_mbm_swint)\n",
    "df_mbm_swint = add_level_pred(df_mbm_swint)\n",
    "mbm_swint = evaluate(df_mbm_swint,method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mbm_swint\n",
    "def plt_roc_curve_multiclass(df, classnames=('negative','ASC','AGC','Organisms'), save_fig = False, return_res=False):\n",
    "    class_ids = list(set(df['class_id']))\n",
    "    class_ids.sort()\n",
    "    class_id_names = dict(zip(range(len(class_ids)),classnames))\n",
    "    colors_list = ['darkorange','deeppink', 'cornflowerblue','aqua']\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    res = {}\n",
    "    plt.figure()\n",
    "    for i, pos_label in enumerate(class_ids):\n",
    "        class_name = class_id_names[pos_label]\n",
    "        gt = df['class_id']\n",
    "        pred_score = df[class_name]\n",
    "        fpr, tpr, thresholds = roc_curve(gt, pred_score, pos_label=pos_label)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        lw = 1.5\n",
    "        res[class_name]=[fpr, tpr]\n",
    "        plt.plot(fpr, tpr, color=colors_list[i],\n",
    "                 lw=lw, label='{} AUC = {:.3f}'.format(class_name, roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "    doctor_fpr_tpr_v1 = [0.062267152511992795, 0.8034326881370635]\n",
    "    doctor_fpr_tpr_v2 = [0.05344528593653488, 0.8211803296464975]\n",
    "    res['doctor1'] = doctor_fpr_tpr_v1\n",
    "    res['doctor2'] = doctor_fpr_tpr_v2\n",
    "    plt.plot(doctor_fpr_tpr_v1[0], doctor_fpr_tpr_v1[1], marker=\"o\", markersize=6, markeredgecolor=\"black\", markerfacecolor=\"orange\") #markerfacecolor=\"green\"\n",
    "    plt.plot(doctor_fpr_tpr_v2[0], doctor_fpr_tpr_v2[1], marker=\"o\", markersize=6, markeredgecolor=\"black\", markerfacecolor=\"orange\") #markerfacecolor=\"green\"\n",
    "    if save_fig:\n",
    "        plt.savefig('hierarchy_roc.png',dpi=300)\n",
    "    plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_alpha(csv_file):\n",
    "    df_alpha =  pd.read_csv(csv_file)\n",
    "    df_alpha = add_order_family_pred_score(df_alpha)\n",
    "    df_alpha = add_level_pred(df_alpha)\n",
    "    alpha = evaluate(df_alpha, method=2)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare alpha\n",
    "# alpha2 = compare_alpha('classification_hierarchy/making-better-mistakes-swinT/hxe_tct_alpha0.4_0412_alpha0.2/test_image_path_mbm_res.csv')\n",
    "# alpha3 = compare_alpha('classification_hierarchy/making-better-mistakes-swinT/hxe_tct_alpha0.4_0412_alpha0.3/test_image_path_mbm_res.csv')\n",
    "# alpha4 = compare_alpha('test_image_path_mbm_res_api_swint_epoch30.csv')\n",
    "# alpha5 = compare_alpha('classification_hierarchy/making-better-mistakes-swinT/hxe_tct_alpha0.4_0412_alpha0.5/test_image_path_mbm_res.csv')\n",
    "# alpha6 = compare_alpha('classification_hierarchy/making-better-mistakes-swinT/hxe_tct_alpha0.4_0412_alpha0.6/test_image_path_mbm_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1_acc</th>\n",
       "      <th>level_2_acc</th>\n",
       "      <th>level_3_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "      <th>level_1_hier_dist</th>\n",
       "      <th>level_2_hier_dist</th>\n",
       "      <th>level_3_hier_dist</th>\n",
       "      <th>avg_hier_dist</th>\n",
       "      <th>level_1_auc</th>\n",
       "      <th>level_2_auc</th>\n",
       "      <th>level_3_auc</th>\n",
       "      <th>level_1_f1_score</th>\n",
       "      <th>level_2_f1_score</th>\n",
       "      <th>level_3_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>0.7852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.2081</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>0.7984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.8002</td>\n",
       "      <td>0.7942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>0.7907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_1_acc  level_2_acc  level_3_acc  avg_acc  level_1_hier_dist  \\\n",
       "0.2       0.9188       0.7779       0.7773   0.8246             0.0563   \n",
       "0.3       0.9195       0.7845       0.7839   0.8293             0.0558   \n",
       "0.4       0.9208       0.7836       0.7835   0.8293             0.0549   \n",
       "0.5       0.9152       0.7807       0.7802   0.8254             0.0588   \n",
       "0.6       0.9188       0.7839       0.7833   0.8287             0.0563   \n",
       "\n",
       "     level_2_hier_dist  level_3_hier_dist  avg_hier_dist  level_1_auc  \\\n",
       "0.2             0.1875             0.2166         0.1535       0.9860   \n",
       "0.3             0.1824             0.2081         0.1488       0.9862   \n",
       "0.4             0.1821             0.2082         0.1484       0.9870   \n",
       "0.5             0.1867             0.2149         0.1535       0.9859   \n",
       "0.6             0.1831             0.2101         0.1498       0.9873   \n",
       "\n",
       "     level_2_auc  level_3_auc  level_1_f1_score  level_2_f1_score  \\\n",
       "0.2       0.9804       0.9808            0.9103            0.7953   \n",
       "0.3       0.9820       0.9827            0.9148            0.8040   \n",
       "0.4       0.9824       0.9829            0.9165            0.8002   \n",
       "0.5       0.9822       0.9830            0.9092            0.7962   \n",
       "0.6       0.9821       0.9832            0.9149            0.8006   \n",
       "\n",
       "     level_3_f1_score  \n",
       "0.2            0.7852  \n",
       "0.3            0.7984  \n",
       "0.4            0.7942  \n",
       "0.5            0.7875  \n",
       "0.6            0.7907  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_alpha = get_res_summary([alpha2, alpha3,  alpha4, alpha5, alpha6], [0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "df_summary_alpha\n",
    "# df_summary_alpha.to_csv('hierarchy_0412/comparison_summary_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.9085\n",
      "level_1 hierarchical distanse: 0.0635\n",
      "##############################\n",
      "Level_2 accuracy: 0.7229\n",
      "level_2 hierarchical distande: 0.2344\n",
      "##############################\n",
      "Level_3 accuracy: 0.7115\n",
      "level_3 hierarchical distande: 0.2886\n",
      "##############################\n",
      "Average accuracy: 0.7810\n",
      "Average hierarchical distance: 0.1955\n"
     ]
    }
   ],
   "source": [
    "df_FGoN = pd.read_csv('classification_hierarchy/FGoN/output_0412_384/test_image_path_res.csv')\n",
    "df_FGoN = add_level_pred(df_FGoN)\n",
    "FGoN2 = evaluate(df_FGoN,method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.9014\n",
      "level_1 hierarchical distanse: 0.0684\n",
      "##############################\n",
      "Level_2 accuracy: 0.7435\n",
      "level_2 hierarchical distande: 0.2198\n",
      "##############################\n",
      "Level_3 accuracy: 0.7665\n",
      "level_3 hierarchical distande: 0.2253\n",
      "##############################\n",
      "Average accuracy: 0.8038\n",
      "Average hierarchical distance: 0.1712\n"
     ]
    }
   ],
   "source": [
    "## HRN \n",
    "df_hrn = pd.read_csv('classification_hierarchy/test_image_path_hrn_res.csv')\n",
    "# multiple binary sigmoid for multi-class classification\n",
    "df_hrn[['order_' + x for x in level_1_names]] = softmax(df_hrn.filter(regex='order*',axis=1).to_numpy(), axis = 1)\n",
    "df_hrn[['family_' + x for x in level_2_names]] = softmax(df_hrn.filter(regex='family*',axis=1).to_numpy(), axis = 1)\n",
    "df_hrn[['species_' + x for x in level_3_names]] = softmax(df_hrn.filter(regex='species*',axis=1).to_numpy(), axis = 1)\n",
    "df_hrn = add_level_pred(df_hrn)\n",
    "hrn2 = evaluate(df_hrn,method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_2_class_acc = {}\n",
    "level_2_class_recall = {}\n",
    "level_2_class_precision = {}\n",
    "for class_name in level_2_names:\n",
    "    df_sub = df_lht[df_lht['level_2'].isin([class_name])]\n",
    "    level_2_class_acc[class_name]=accuracy_score(df_sub['level_1'],df_sub['level_1_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(df_families, to_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.9125\n",
      "level_1 hierarchical distanse: 0.0607\n",
      "##############################\n",
      "Level_2 accuracy: 0.7813\n",
      "level_2 hierarchical distande: 0.1871\n",
      "##############################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9124676072559746,\n",
       " 0.7813129858911604,\n",
       " 0.06067283123818697,\n",
       " 0.1870736183415377,\n",
       " 0.9864062338514833,\n",
       " 0.982281043867004]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### order & family two level classification with making better mistakes\n",
    "# df_families = pd.read_csv('csv_results/test_image_path_mbm_2level_res.csv')\n",
    "df_families = pd.read_csv('csv_results/test_image_path_mbm_res_0512_swinT_2levels.csv')\n",
    "df_families = add_order_pred_score(df_families)\n",
    "df_families['level_2_pred'] = [x.split('_')[-1] for x in df_families.filter(regex='family*',axis=1).idxmax(axis=1)]\n",
    "df_families['level_1_pred'] = df_families['level_2_pred'].apply(lambda x: find_level_name_v2(x, level=1))\n",
    "# df_families['level_2_id'] = df_families['level_2'].apply(lambda x: level_2_names2id.get(x, -1))\n",
    "evaluate(df_families, to_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8619\n",
      "level_1 hierarchical distanse: 0.0957\n",
      "##############################\n",
      "Level_2 accuracy: 0.7037\n",
      "level_2 hierarchical distande: 0.2613\n",
      "##############################\n",
      "Level_3 accuracy: 0.7679\n",
      "level_3 hierarchical distande: 0.2303\n",
      "##############################\n",
      "Average accuracy: 0.7778\n",
      "Average hierarchical distance: 0.1958\n"
     ]
    }
   ],
   "source": [
    "### species fine-grained visual classification\n",
    "df_api_net = pd.read_csv('/classification_FGVC/API-Net-master-384/test_image_path_keep_species_all_res.csv')\n",
    "df_api_net = add_order_family_pred_score(df_api_net)\n",
    "df_api_net = fgvc_helper(df_api_net)\n",
    "api_net2 = evaluate(df_api_net, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8555\n",
      "level_1 hierarchical distanse: 0.1001\n",
      "##############################\n",
      "Level_2 accuracy: 0.7000\n",
      "level_2 hierarchical distande: 0.2649\n",
      "##############################\n",
      "Level_3 accuracy: 0.7620\n",
      "level_3 hierarchical distande: 0.2386\n",
      "##############################\n",
      "Average accuracy: 0.7725\n",
      "Average hierarchical distance: 0.2012\n"
     ]
    }
   ],
   "source": [
    "## CAL model\n",
    "df_cal = pd.read_csv('classification_FGVC/CAL/fgvc/test_image_path_keep_species_all_res.csv')\n",
    "df_cal = add_order_family_pred_score(df_cal)\n",
    "df_cal = fgvc_helper(df_cal)\n",
    "cal2 = evaluate(df_cal, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8675\n",
      "level_1 hierarchical distanse: 0.0919\n",
      "##############################\n",
      "Level_2 accuracy: 0.7080\n",
      "level_2 hierarchical distande: 0.2558\n",
      "##############################\n",
      "Level_3 accuracy: 0.7738\n",
      "level_3 hierarchical distande: 0.2234\n",
      "##############################\n",
      "Average accuracy: 0.7831\n",
      "Average hierarchical distance: 0.1903\n"
     ]
    }
   ],
   "source": [
    "##  swinT\n",
    "df_swint = pd.read_csv('classification_hierarchy/vanilla_species_384/output_0512_swint/test_image_path_keep_species_all_res.csv')\n",
    "df_swint = add_order_family_pred_score(df_swint)\n",
    "df_swint = fgvc_helper(df_swint)\n",
    "swint = evaluate(df_swint, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8649\n",
      "level_1 hierarchical distanse: 0.0937\n",
      "##############################\n",
      "Level_2 accuracy: 0.7011\n",
      "level_2 hierarchical distande: 0.2608\n",
      "##############################\n",
      "Level_3 accuracy: 0.7633\n",
      "level_3 hierarchical distande: 0.2326\n",
      "##############################\n",
      "Average accuracy: 0.7764\n",
      "Average hierarchical distance: 0.1957\n"
     ]
    }
   ],
   "source": [
    "## FGVC-PIM model\n",
    "df_pim = pd.read_csv('classification_FGVC/FGVC-PIM-master/test_image_path_keep_species_all_res.csv')\n",
    "df_pim = add_order_family_pred_score(df_pim)\n",
    "df_pim = fgvc_helper(df_pim)\n",
    "pim2 = evaluate(df_pim, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_summary_fgvc = get_res_summary([transfg2, cal2, pim2, api_net2], ['TranFG', 'CAL', 'FGVC-PIM', 'API-net'])\n",
    "# df_summary_fgvc\n",
    "# df_summary_fgvc.to_csv('hierarchy_0412/comparison_summary_res_fgvc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8629\n",
      "level_1 hierarchical distanse: 0.0950\n",
      "##############################\n",
      "Level_2 accuracy: 0.7055\n",
      "level_2 hierarchical distande: 0.2595\n",
      "##############################\n",
      "Level_3 accuracy: 0.7658\n",
      "level_3 hierarchical distande: 0.2312\n",
      "##############################\n",
      "Average accuracy: 0.7781\n",
      "Average hierarchical distance: 0.1953\n"
     ]
    }
   ],
   "source": [
    "# resnet50 model \n",
    "df_resnet50 = pd.read_csv('classification_hierarchy/vanilla_species/output_0512_resnet50_384/test_image_path_keep_species_all_res.csv')\n",
    "df_resnet50 = add_order_family_pred_score(df_resnet50)\n",
    "df_resnet50 = fgvc_helper(df_resnet50)\n",
    "resnet50 = evaluate(df_resnet50, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resnet101 = pd.read_csv('classification_hierarchy/vanilla_species/output_0512_resnet101/test_image_path_keep_species_all_res.csv')\n",
    "# df_resnet101 = add_order_family_pred_score(df_resnet101)\n",
    "# df_resnet101 = fgvc_helper(df_resnet101)\n",
    "# resnet101 = evaluate(df_resnet101, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8673\n",
      "level_1 hierarchical distanse: 0.0919\n",
      "##############################\n",
      "Level_2 accuracy: 0.7037\n",
      "level_2 hierarchical distande: 0.2593\n",
      "##############################\n",
      "Level_3 accuracy: 0.7665\n",
      "level_3 hierarchical distande: 0.2260\n",
      "##############################\n",
      "Average accuracy: 0.7792\n",
      "Average hierarchical distance: 0.1924\n"
     ]
    }
   ],
   "source": [
    "df_efficientnet = pd.read_csv('classification_hierarchy/vanilla_species/output_0512_efficientnet_b3_384/test_image_path_keep_species_all_res.csv')\n",
    "df_efficientnet = add_order_family_pred_score(df_efficientnet)\n",
    "df_efficientnet = fgvc_helper(df_efficientnet)\n",
    "efficientnet = evaluate(df_efficientnet, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all data...\n",
      "Level_1 accuracy: 0.8629\n",
      "level_1 hierarchical distanse: 0.0950\n",
      "##############################\n",
      "Level_2 accuracy: 0.7055\n",
      "level_2 hierarchical distande: 0.2597\n",
      "##############################\n",
      "Level_3 accuracy: 0.7666\n",
      "level_3 hierarchical distande: 0.2341\n",
      "##############################\n",
      "Average accuracy: 0.7783\n",
      "Average hierarchical distance: 0.1963\n"
     ]
    }
   ],
   "source": [
    "#mobilenet\n",
    "df_mobilenet = pd.read_csv('classification_hierarchy/vanilla_species/output_0512_mobilenet_v2_384/test_image_path_keep_species_all_res.csv')\n",
    "df_mobilenet = add_order_family_pred_score(df_mobilenet)\n",
    "df_mobilenet = fgvc_helper(df_mobilenet)\n",
    "mobilenet = evaluate(df_mobilenet, method=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1_acc</th>\n",
       "      <th>level_2_acc</th>\n",
       "      <th>level_3_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "      <th>level_1_hier_dist</th>\n",
       "      <th>level_2_hier_dist</th>\n",
       "      <th>level_3_hier_dist</th>\n",
       "      <th>avg_hier_dist</th>\n",
       "      <th>level_1_auc</th>\n",
       "      <th>level_2_auc</th>\n",
       "      <th>level_3_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>0.8629</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenet</th>\n",
       "      <td>0.8629</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.9831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet</th>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.7792</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHN</th>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.3605</td>\n",
       "      <td>0.2486</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.8425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGoN</th>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.7810</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRN</th>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBM</th>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.2396</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAL</th>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.9821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>API-Net</th>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.7744</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.9799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGVC-PIM</th>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.2326</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swint</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HierSwin</th>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.9829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              level_1_acc  level_2_acc  level_3_acc  avg_acc  \\\n",
       "resnet50           0.8629       0.7055       0.7658   0.7781   \n",
       "mobilenet          0.8629       0.7055       0.7666   0.7783   \n",
       "efficientnet       0.8673       0.7037       0.7665   0.7792   \n",
       "MHN                0.8809       0.6406       0.6389   0.7201   \n",
       "FGoN               0.9085       0.7229       0.7115   0.7810   \n",
       "HRN                0.9014       0.7435       0.7665   0.8038   \n",
       "MBM                0.9048       0.7577       0.7566   0.8064   \n",
       "CAL                0.8555       0.7000       0.7620   0.7725   \n",
       "API-Net            0.8604       0.6994       0.7635   0.7744   \n",
       "FGVC-PIM           0.8649       0.7011       0.7633   0.7764   \n",
       "swint              0.8675       0.7080       0.7738   0.7831   \n",
       "HierSwin           0.9208       0.7836       0.7835   0.8293   \n",
       "\n",
       "              level_1_hier_dist  level_2_hier_dist  level_3_hier_dist  \\\n",
       "resnet50                 0.0950             0.2595             0.2312   \n",
       "mobilenet                0.0950             0.2597             0.2341   \n",
       "efficientnet             0.0919             0.2593             0.2260   \n",
       "MHN                      0.0826             0.3028             0.3605   \n",
       "FGoN                     0.0635             0.2344             0.2886   \n",
       "HRN                      0.0684             0.2198             0.2253   \n",
       "MBM                      0.0660             0.2072             0.2396   \n",
       "CAL                      0.1001             0.2649             0.2386   \n",
       "API-Net                  0.0968             0.2640             0.2353   \n",
       "FGVC-PIM                 0.0937             0.2608             0.2326   \n",
       "swint                    0.0919             0.2558             0.2234   \n",
       "HierSwin                 0.0549             0.1821             0.2082   \n",
       "\n",
       "              avg_hier_dist  level_1_auc  level_2_auc  level_3_auc  \n",
       "resnet50             0.1953       0.9726       0.9674       0.9828  \n",
       "mobilenet            0.1963       0.9742       0.9693       0.9831  \n",
       "efficientnet         0.1924       0.9747       0.9682       0.9815  \n",
       "MHN                  0.2486       0.9692       0.8714       0.8425  \n",
       "FGoN                 0.1955       0.9759       0.9375       0.9252  \n",
       "HRN                  0.1712       0.9784       0.9352       0.9810  \n",
       "MBM                  0.1709       0.9818       0.9790       0.9798  \n",
       "CAL                  0.2012       0.9739       0.9693       0.9821  \n",
       "API-Net              0.1987       0.9744       0.9627       0.9799  \n",
       "FGVC-PIM             0.1957       0.9729       0.9671       0.9805  \n",
       "swint                0.1903       0.9750       0.9664       0.9810  \n",
       "HierSwin             0.1484       0.9870       0.9824       0.9829  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = get_res_summary([resnet50, mobilenet, efficientnet, multi2, FGoN2, hrn2, mbm2, cal2, api_net2, pim2, swint, mbm_swint],\n",
    "                             ['resnet50', 'mobilenet','efficientnet','MHN','FGoN', 'HRN','MBM','CAL', 'API-Net','FGVC-PIM','swint', 'HierSwin'])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('hierarchy_0412/benchmark_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tct_trees = np.array([[0, 0, 0],\n",
    "                     [0, 1, 1],\n",
    "                     [0, 2, 2],\n",
    "                     [0, 3, 3],\n",
    "                     [0, 4, 4],\n",
    "                     [0, 5, 5],\n",
    "                     [0, 6, 6],\n",
    "                     [0, 7, 7],\n",
    "                     [1, 8, 8],\n",
    "                     [1, 9, 9],\n",
    "                     [1, 10, 10],\n",
    "                     [1, 11, 11],\n",
    "                     [1, 12, 12],\n",
    "                     [2, -1, -1],\n",
    "                     [2, 13, -1],\n",
    "                     [2, 14, 13],\n",
    "                     [2, 15, -1],\n",
    "                     [2, 13, 14],\n",
    "                     [2, 13, 15],\n",
    "                     [2, 15, 16],\n",
    "                     [2, 15, 17],\n",
    "                     [3, 16, 18],\n",
    "                     [3, 17, 19],\n",
    "                     [3, 18, 20],\n",
    "                     [3, 19, 21],\n",
    "                     [3, 20, 22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(tct_trees[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4+21+23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0~3, 4~24, 25~47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tct_trees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 'Normal'),\n",
       "             (1, 'ECC'),\n",
       "             (2, 'RPC'),\n",
       "             (3, 'MPC'),\n",
       "             (4, 'PG'),\n",
       "             (5, 'Atrophy'),\n",
       "             (6, 'EMC'),\n",
       "             (7, 'HCG '),\n",
       "             (8, 'ASC-US'),\n",
       "             (9, 'LSIL'),\n",
       "             (10, 'ASC-H'),\n",
       "             (11, 'HSIL'),\n",
       "             (12, 'SCC'),\n",
       "             (15, 'AGC-FN'),\n",
       "             (17, 'AGC-ECC-NOS'),\n",
       "             (18, 'AGC-EMC-NOS'),\n",
       "             (19, 'ADC-ECC'),\n",
       "             (20, 'ADC-EMC'),\n",
       "             (21, 'FUNGI'),\n",
       "             (22, 'ACTINO'),\n",
       "             (23, 'TRI'),\n",
       "             (24, 'HSV'),\n",
       "             (25, 'CC')])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id2class_name = dict(zip(df['class_id'],df['class_name']))\n",
    "class_id2class_name = OrderedDict(sorted(class_id2class_name.items())) \n",
    "class_id2class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # species, order, family\n",
    "num_species = 23\n",
    "num_family = 21\n",
    "num_order = 4\n",
    "families_interval = [1,]*num_family\n",
    "families_interval[13] = 2\n",
    "families_interval[15] = 2\n",
    "order_interval = [8, 5, 5, 5]\n",
    "tct_trees0 = np.zeros((num_species,3),dtype=np.int)\n",
    "tct_trees0[:,0] = np.arange(23)# + num_family + num_order\n",
    "family_inds = []\n",
    "for i in range(num_family):\n",
    "    family_inds.extend([i]*families_interval[i])\n",
    "\n",
    "order_inds = []\n",
    "for i in range(num_order):\n",
    "    order_inds.extend([i]*order_interval[i])\n",
    "tct_trees0[:,1] = order_inds\n",
    "tct_trees0[:,2] = family_inds\n",
    "\n",
    "tct_trees1 = tct_trees0.copy()\n",
    "tct_trees1[:,0] += num_family + num_order\n",
    "tct_trees1[:,2] += num_order\n",
    "tct_trees2 = tct_trees0.copy()\n",
    "tct_trees2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tct_trees1\n",
    "# tct_trees2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
