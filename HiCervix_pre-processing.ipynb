{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "from pprint import pprint\n",
    "# import cv2\n",
    "# import imageio\n",
    "# import imagesize\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby,chain,combinations\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, cohen_kappa_score, accuracy_score\n",
    "from sklearn.metrics import average_precision_score, roc_curve, auc, precision_recall_curve, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree, search\n",
    "from anytree.importer import JsonImporter\n",
    "from anytree.exporter import JsonExporter, DotExporter\n",
    "import lzma\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install anytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lca_height(class_name1, class_name2, logarithmic=True):\n",
    "    \"\"\"lowest common ancestor height, taking the level into acount np.log(1+height)\n",
    "    \"\"\"\n",
    "    node1 = search.find_by_attr(TCT, class_name1)\n",
    "    node2 = search.find_by_attr(TCT, class_name2)\n",
    "    node1_path_names = [x.name for x in node1.path]\n",
    "    node2_path_names = [x.name for x in node2.path]\n",
    "    if len(node1_path_names) == len(node2_path_names):\n",
    "        height = 0\n",
    "        for name1, name2 in list(zip(node1_path_names, node2_path_names))[::-1]:\n",
    "            if name1==name2:\n",
    "                return np.log(1+height) if logarithmic else height\n",
    "            else:\n",
    "                height +=1\n",
    "    #             return name1\n",
    "    else:\n",
    "        common_length = len(set(node1_path_names).intersection(set(node2_path_names)))\n",
    "        longest_length = max(len(node1_path_names), len(node2_path_names))\n",
    "        height = longest_length - common_length\n",
    "        return height\n",
    "def find_level_name_v2(class_name, level=1):\n",
    "    \"\"\"fill the finest label using the coarse lable\"\"\"\n",
    "    path_node_classes = classname_paths[class_name.strip()]\n",
    "    if len(path_node_classes)>level:\n",
    "        return path_node_classes[level]\n",
    "    else:\n",
    "        return path_node_classes[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchy class in HiCervix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### hierarchical tree construction for HiCervix\n",
    "## the full names of the acronyms are listed in dataset/hierarchy_classification/version2023/hierarchy_names.csv\n",
    "TCT = Node(\"TCT\")\n",
    "negative = Node(\"negative\",parent=TCT) \n",
    "ASC = Node(\"ASC\", parent=TCT) \n",
    "AGC = Node(\"AGC\", parent=TCT) \n",
    "microbe = Node(\"microbe\",parent=TCT)  ## microbe is the class  Organisms\n",
    "\n",
    "ASCUS = Node(\"ASC-US\", parent=ASC)\n",
    "LSIL = Node(\"LSIL\", parent=ASC)\n",
    "ASCH = Node(\"ASC-H\", parent=ASC)\n",
    "HSIL = Node(\"HSIL\", parent=ASC)\n",
    "SCC = Node(\"SCC\", parent=ASC)\n",
    "\n",
    "AGCNOS = Node(\"AGC-NOS\", parent=AGC)\n",
    "AGCFN = Node(\"AGC-FN\", parent=AGC)\n",
    "ADC = Node(\"ADC\", parent=AGC)\n",
    "\n",
    "AGCNOS1 = Node(\"AGC-ECC-NOS\", parent=AGCNOS)\n",
    "AGCNOS2 = Node(\"AGC-EMC-NOS\", parent=AGCNOS)\n",
    "\n",
    "ADC1 = Node(\"ADC-ECC\", parent=ADC)\n",
    "ADC2 = Node(\"ADC-EMC\", parent=ADC)\n",
    "\n",
    "normal = Node(\"Normal\", parent=negative)\n",
    "endocervical = Node(\"ECC\", parent=negative)\n",
    "xiufu = Node(\"RPC\", parent=negative)\n",
    "huasheng = Node(\"MPC\", parent=negative)\n",
    "glucose = Node(\"PG\", parent=negative)\n",
    "Atrophy = Node(\"Atrophy\", parent=negative)\n",
    "EMC = Node(\"EMC\", parent=negative)\n",
    "HCG = Node(\"HCG\", parent=negative)\n",
    "\n",
    "FUNGI = Node(\"FUNGI\", parent=microbe)\n",
    "ACTINO = Node(\"ACTINO\", parent=microbe)\n",
    "TRI = Node(\"TRI\", parent=microbe)\n",
    "HSV = Node(\"HSV\", parent=microbe)\n",
    "CC = Node(\"CC\", parent=microbe)\n",
    "\n",
    "# DotExporter(TCT_en).to_picture(\"TCT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total annotated classes: 26\n",
      "Number of level 1 classes: 4\n",
      "Number of level 2 classes: 21\n",
      "Number of level 3 classes: 23\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG', 'ASC-US', 'LSIL',\n",
    "               'ASC-H', 'HSIL', 'SCC', 'AGC', 'AGC-NOS', 'AGC-FN', 'ADC', 'AGC-ECC-NOS', 'AGC-EMC-NOS', \n",
    "               'ADC-ECC', 'ADC-EMC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "level_1_names = ['negative','ASC','AGC','microbe']\n",
    "level_2_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG', 'ASC-US', 'LSIL', \n",
    "                 'ASC-H', 'HSIL', 'SCC', 'AGC-NOS', 'AGC-FN', 'ADC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "level_3_names = ['Normal', 'ECC', 'RPC', 'MPC', 'PG', 'Atrophy', 'EMC', 'HCG', 'ASC-US', 'LSIL', 'ASC-H', 'HSIL', 'SCC', 'AGC-FN', \n",
    "                 'AGC-ECC-NOS', 'AGC-EMC-NOS', 'ADC-ECC', 'ADC-EMC', 'FUNGI', 'ACTINO', 'TRI', 'HSV', 'CC']\n",
    "level_1_names2id = dict(zip(level_1_names, range(len(level_1_names))))\n",
    "level_2_names2id = dict(zip(level_2_names, range(len(level_2_names))))\n",
    "level_3_names2id = dict(zip(level_3_names, range(len(level_3_names))))\n",
    "\n",
    "level_names = [level_1_names, level_2_names,level_3_names,]\n",
    "classname2newid = dict(zip(class_names, range(len(class_names))))\n",
    "newid2classname= {v:k for k,v in classname2newid.items()}\n",
    "print('Number of total annotated classes: {}'.format(len(class_names)))\n",
    "for i in range(3):\n",
    "    print('Number of level {} classes: {}'.format(i+1, len(level_names[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classname_paths = {}\n",
    "for class_name in class_names:\n",
    "    # print(class_name)\n",
    "    class_name_node = search.find_by_attr(TCT, class_name)\n",
    "    path_node_classes = [x.name for x in class_name_node.path]#[1:] #exclude the root node of 'TCT'\n",
    "#     print('The nodes in the path (from root node) to reach the nodes of {}'.format(class_name))\n",
    "#     print(path_node_classes)\n",
    "    classname_paths[class_name] = path_node_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': ['TCT', 'negative', 'Normal'],\n",
       " 'ECC': ['TCT', 'negative', 'ECC'],\n",
       " 'RPC': ['TCT', 'negative', 'RPC'],\n",
       " 'MPC': ['TCT', 'negative', 'MPC'],\n",
       " 'PG': ['TCT', 'negative', 'PG'],\n",
       " 'Atrophy': ['TCT', 'negative', 'Atrophy'],\n",
       " 'EMC': ['TCT', 'negative', 'EMC'],\n",
       " 'HCG': ['TCT', 'negative', 'HCG'],\n",
       " 'ASC-US': ['TCT', 'ASC', 'ASC-US'],\n",
       " 'LSIL': ['TCT', 'ASC', 'LSIL'],\n",
       " 'ASC-H': ['TCT', 'ASC', 'ASC-H'],\n",
       " 'HSIL': ['TCT', 'ASC', 'HSIL'],\n",
       " 'SCC': ['TCT', 'ASC', 'SCC'],\n",
       " 'AGC': ['TCT', 'AGC'],\n",
       " 'AGC-NOS': ['TCT', 'AGC', 'AGC-NOS'],\n",
       " 'AGC-FN': ['TCT', 'AGC', 'AGC-FN'],\n",
       " 'ADC': ['TCT', 'AGC', 'ADC'],\n",
       " 'AGC-ECC-NOS': ['TCT', 'AGC', 'AGC-NOS', 'AGC-ECC-NOS'],\n",
       " 'AGC-EMC-NOS': ['TCT', 'AGC', 'AGC-NOS', 'AGC-EMC-NOS'],\n",
       " 'ADC-ECC': ['TCT', 'AGC', 'ADC', 'ADC-ECC'],\n",
       " 'ADC-EMC': ['TCT', 'AGC', 'ADC', 'ADC-EMC'],\n",
       " 'FUNGI': ['TCT', 'microbe', 'FUNGI'],\n",
       " 'ACTINO': ['TCT', 'microbe', 'ACTINO'],\n",
       " 'TRI': ['TCT', 'microbe', 'TRI'],\n",
       " 'HSV': ['TCT', 'microbe', 'HSV'],\n",
       " 'CC': ['TCT', 'microbe', 'CC']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classname_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing for different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hierarchy for HierSwin and making better mistakes\n",
    "tct = Tree.fromstring(\"(TCT (negative (Normal Normal) (ECC ECC) (RPC RPC) (MPC MPC) (PG PG) (Atrophy Atrophy) (EMC EMC) (HCG HCG))  \\\n",
    "                     (ASC (ASC-US ASC-US) (LSIL LSIL) (ASC-H ASC-H) (HSIL HSIL) (SCC SCC))   \\\n",
    "                     (AGC (AGC-FN AGC-FN) (AGC-NOS AGC-ECC-NOS AGC-EMC-NOS) (ADC ADC-ECC ADC-EMC)) \\\n",
    "                     (microbe (FUNGI FUNGI) (ACTINO ACTINO) (TRI TRI) (HSV HSV) (CC CC)) \\\n",
    "                     )\")\n",
    "tct_2level = Tree.fromstring(\"(TCT (negative Normal  ECC RPC MPC  PG  Atrophy  EMC  HCG)  \\\n",
    "                     (ASC  ASC-US  LSIL  ASC-H  HSIL  SCC)   \\\n",
    "                     (AGC AGC-FN  AGC-NOS  ADC ) \\\n",
    "                     (microbe  FUNGI  ACTINO  TRI  HSV  CC) \\\n",
    "                     )\")\n",
    "\n",
    "tct_distances = {}\n",
    "all_names = set(level_1_names + level_2_names + level_3_names)\n",
    "for name1 in all_names:\n",
    "    for name2 in all_names:\n",
    "        tct_distances[(name1,name2)] = lca_height(name1, name2)\n",
    "with open('tct_tree.pkl','wb') as fi:\n",
    "    pickle.dump(tct, fi)\n",
    "\n",
    "with open('tct_distances.pkl','wb') as fi:\n",
    "    pickle.dump(tct_distances, fi)\n",
    "\n",
    "level_names_dict = dict(zip(['order','family','species'], level_names))\n",
    "with open('level_names_dict.pkl','wb') as fi:\n",
    "    pickle.dump(level_names_dict, fi)\n",
    "# with open('classification_hierarchy/making-better-mistakes-2level/data/tct_tree.pkl','wb') as fi:\n",
    "#     pickle.dump(tct_2level, fi)\n",
    "\n",
    "# with open('classification_hierarchy/making-better-mistakes/data/tct_tree.pkl','rb') as fi:\n",
    "#     tree_data = pickle.load(fi)\n",
    "# tree_data\n",
    "# with lzma.open('/classification_hierarchy/making-better-mistakes/data/imagenet_ilsvrc_distances.pkl.xz', \"rb\") as f:\n",
    "#     tmp = pickle.load(f)\n",
    "# #     distance_data = DistanceDict(pickle.load(f))\n",
    "#     distance_data = DistanceDict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# level_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for multi-head and FGoN\n",
    "trees =[]\n",
    "trees_names = []\n",
    "trees_dict = {}\n",
    "def find_class_id(class_name, lst):\n",
    "    try:\n",
    "        class_id = lst.index(class_name)\n",
    "    except:\n",
    "        class_id = -1\n",
    "    return class_id\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_name_node = search.find_by_attr(TCT, class_name)\n",
    "    path_node_classes = [x.name for x in class_name_node.path]#[1:] #exclude the root node of 'TCT'\n",
    "    extended_node_names = [find_level_name_v2(class_name, i) for i in range(1,4)]\n",
    "    extended_node_ids = [find_class_id(x, level_names[i]) for i, x in enumerate(extended_node_names)] #level_names[i].index(x)\n",
    "    trees.append(extended_node_ids)\n",
    "    trees_names.append(extended_node_names)\n",
    "    trees_dict[class_name]=extended_node_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HierSwin methods and making better mistakes\n",
    "datasets = ['train.csv','val.csv','test.csv']\n",
    "# datasets = ['train_image_path.csv','val_image_path.csv','test_image_path.csv']\n",
    "csv_dir = 'dataset/hierarchy_classification/version2023/'\n",
    "for dataset in datasets:\n",
    "    csv_file = osp.join(csv_dir, dataset)\n",
    "    df_tmp = pd.read_csv(csv_file)\n",
    "    df_tmp = df_tmp[df_tmp['class_name'].isin(level_3_names)]\n",
    "    df_tmp['level_3_id'] = df_tmp['class_name'].map(dict(zip(level_3_names,range(len(level_3_names)))))\n",
    "    df_tmp.to_csv(csv_file.replace('.csv','_mbm.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HRN\n",
    "datasets = ['train_image_path.csv']#,'val_image_path.csv','test_image_path.csv']\n",
    "csv_dir = 'dataset/hierarchy_classification/version2023/'\n",
    "for dataset in datasets:\n",
    "    csv_file = osp.join(csv_dir, dataset)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['level_1_id'] = df['level_1'].map(level_1_names2id)\n",
    "    df['level_2_name'] = df['class_name'].apply(lambda x: find_level_name_v2(x, level=2))\n",
    "    df['level_3_name'] = df['class_name'].apply(lambda x: find_level_name_v2(x, level=3))\n",
    "    df['level_2_id'] = df['level_2_name'].apply(lambda x: level_2_names2id.get(x, -1))\n",
    "    df['level_3_id'] = df['level_3_name'].apply(lambda x: level_3_names2id.get(x, -1))\n",
    "    #df[['image_path', 'image_name', 'class_id', 'level_1_id', 'level_2_id', 'level_3_id']].to_csv(csv_file.replace('.csv','_hrn.csv')) #encoding='utf-8-sig', ,  index=False\n",
    "    df[['image_path', 'image_name', 'class_id', 'level_1_id', 'level_2_id', 'level_3_id']].to_csv('/mnt/group-ai-medical-abp/private/daviddecai/tmp.csv') #encoding='utf-8-sig', ,  index=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fine-grained visual classification\n",
    "\n",
    "# level_3 finegrainedï¼Œintermediate classes such as AGC,'AGC-NOS','ADC' are removed \n",
    "csv_dir = 'dataset/hierarchy_classification/version2023'\n",
    "datasets = ['train','val','test']\n",
    "for dataset in datasets:\n",
    "    df_tmp = pd.read_csv(osp.join(csv_dir, dataset + '.csv'))\n",
    "    #df_tmp = df_tmp[~df_tmp['class_name'].isin(['AGC','AGC-NOS','ADC'])] \n",
    "    df_tmp = df_v2(df_tmp)\n",
    "    #df_tmp['level_3_id']= df_tmp['level_3'].map(dict(zip(level_3_names, range(len(level_3_names)))))\n",
    "    df_tmp['level_3_id']= df_tmp['level_3'].apply(lambda x: level_3_names2id.get(x, -1))\n",
    "    df_tmp.to_csv(osp.join(csv_dir, dataset + '_keep_species_all.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tct_trees = np.array([[0, 0, 0],\n",
    "                     [0, 1, 1],\n",
    "                     [0, 2, 2],\n",
    "                     [0, 3, 3],\n",
    "                     [0, 4, 4],\n",
    "                     [0, 5, 5],\n",
    "                     [0, 6, 6],\n",
    "                     [0, 7, 7],\n",
    "                     [1, 8, 8],\n",
    "                     [1, 9, 9],\n",
    "                     [1, 10, 10],\n",
    "                     [1, 11, 11],\n",
    "                     [1, 12, 12],\n",
    "                     [2, -1, -1],\n",
    "                     [2, 13, -1],\n",
    "                     [2, 14, 13],\n",
    "                     [2, 15, -1],\n",
    "                     [2, 13, 14],\n",
    "                     [2, 13, 15],\n",
    "                     [2, 15, 16],\n",
    "                     [2, 15, 17],\n",
    "                     [3, 16, 18],\n",
    "                     [3, 17, 19],\n",
    "                     [3, 18, 20],\n",
    "                     [3, 19, 21],\n",
    "                     [3, 20, 22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(tct_trees[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4+21+23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0~3, 4~24, 25~47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tct_trees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 'Normal'),\n",
       "             (1, 'ECC'),\n",
       "             (2, 'RPC'),\n",
       "             (3, 'MPC'),\n",
       "             (4, 'PG'),\n",
       "             (5, 'Atrophy'),\n",
       "             (6, 'EMC'),\n",
       "             (7, 'HCG '),\n",
       "             (8, 'ASC-US'),\n",
       "             (9, 'LSIL'),\n",
       "             (10, 'ASC-H'),\n",
       "             (11, 'HSIL'),\n",
       "             (12, 'SCC'),\n",
       "             (15, 'AGC-FN'),\n",
       "             (17, 'AGC-ECC-NOS'),\n",
       "             (18, 'AGC-EMC-NOS'),\n",
       "             (19, 'ADC-ECC'),\n",
       "             (20, 'ADC-EMC'),\n",
       "             (21, 'FUNGI'),\n",
       "             (22, 'ACTINO'),\n",
       "             (23, 'TRI'),\n",
       "             (24, 'HSV'),\n",
       "             (25, 'CC')])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id2class_name = dict(zip(df['class_id'],df['class_name']))\n",
    "class_id2class_name = OrderedDict(sorted(class_id2class_name.items())) \n",
    "class_id2class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # species, order, family\n",
    "num_species = 23\n",
    "num_family = 21\n",
    "num_order = 4\n",
    "families_interval = [1,]*num_family\n",
    "families_interval[13] = 2\n",
    "families_interval[15] = 2\n",
    "order_interval = [8, 5, 5, 5]\n",
    "tct_trees0 = np.zeros((num_species,3),dtype=np.int)\n",
    "tct_trees0[:,0] = np.arange(23)# + num_family + num_order\n",
    "family_inds = []\n",
    "for i in range(num_family):\n",
    "    family_inds.extend([i]*families_interval[i])\n",
    "\n",
    "order_inds = []\n",
    "for i in range(num_order):\n",
    "    order_inds.extend([i]*order_interval[i])\n",
    "tct_trees0[:,1] = order_inds\n",
    "tct_trees0[:,2] = family_inds\n",
    "\n",
    "tct_trees1 = tct_trees0.copy()\n",
    "tct_trees1[:,0] += num_family + num_order\n",
    "tct_trees1[:,2] += num_order\n",
    "tct_trees2 = tct_trees0.copy()\n",
    "tct_trees2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tct_trees1\n",
    "# tct_trees2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
